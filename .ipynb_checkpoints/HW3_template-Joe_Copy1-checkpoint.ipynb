{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2646a34e-a634-47ac-9fe7-73bf40ece8ae",
   "metadata": {},
   "source": [
    "# HW3 Template: Dataset Overview and Use Case Examples\n",
    "## EDS 220, Fall 2021\n",
    "\n",
    "The following is a template you can use for constructing your draft Jupyter notebooks demonstrating the features and use case examples for your chosen environmental datasets. I've included sections addressing the major themes that should be included, but there is also room for customization as well. \n",
    "\n",
    "Many of the resources provided are adapted from this template guide to notebook creation built for the \"EarthCube\" project:\n",
    "https://github.com/earthcube/NotebookTemplates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a405bf-2d38-4175-a931-f52905e11211",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NASA Earth Exchange (NEX) Downscaled Climate Projections (NEX-DCP30) dataset for the conterminous United States\n",
    "\n",
    "The modelled data generated from the General Circulation Model(GCM) runs under 33 different Coupled Model Intercomparison Project Phase 5(CMIP5) models. The modelled data projections are available for four greenhouse gas emissions scenarios known as Representative Concentration Pathways(RCPs) labelled after the range of radiative forcing values in the year 2100 (2.6, 4.5, 6, and 8.5 W/m2).\n",
    "\n",
    "In this notebook we will be building on our python skills by mapping a region of interest and overlaying climate modelling scenarios over that region. This modelling is vital for county governments and economy sectors to begin planning for climate change and understanding how it may effect them directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47afd0-adb0-4d5b-8903-992b7904322e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Authors\n",
    "\n",
    "- Desik Somasundaram, UC Santa Barbara (desik@bren.ucsb.edu ) <br>\n",
    "- Daniel Kerstan, UC Santa Barbara (danielkerstan@bren.ucsb.edu ) <br>\n",
    "- Joe DeCesaro, UC Santa Barbara (jdecesaro@bren.ucsb.edu ) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c2013-fef1-44ac-bb00-3215807cacac",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "Include a summary of the various sections included in your notebook, so that users can easily skip to a section of interest. It's also good to include hyperlinks to the different sections, so that clicking on the heading sends one to that section directly. Examples are below; see also this handy guide to adding hyperlinks to Jupyter notebooks:\n",
    "https://medium.illumidesk.com/jupyter-notebook-little-known-tricks-b0866a558017\n",
    "\n",
    "[1. Purpose](#purpose)\n",
    "\n",
    "[2. Dataset Description](#overview)\n",
    "\n",
    "[3. Data I/O](#io)\n",
    "\n",
    "[4. Metadata Display and Basic Visualization](#display)\n",
    "\n",
    "[5. Use Case Examples](#usecases)\n",
    "\n",
    "[6. Create Binder Environment](#binder)\n",
    "\n",
    "[7. References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52c6e3-3584-48be-b500-21578b61bd72",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "## Notebook Purpose\n",
    "\n",
    "This notebook was produced for the final project of EDS 220 - Remote Sensing. It provides instruction and example code on how to pull in the NASA Earth Exchange climate projection data directly from the source. It provides specific use case examples for this data set. Specifically, this workbook shows how local governments and economy sectors could plan for different climate scenarios from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429260a-2c30-44da-a5af-e100a440056a",
   "metadata": {},
   "source": [
    "<a id='overview'></a> \n",
    "## Dataset Description\n",
    "\n",
    "### General Description\n",
    "The modelled data is generated by NASA from the General Circulation Model(GCM) runs under 33 different Coupled Model Intercomparison Project Phase 5(CMIP5) models. The modelled data projections are available for four greenhouse gas emissions scenarios known as Representative Concentration Pathways(RCPs) labelled after the range of radiative forcing values in the year 2100 (2.6, 4.5, 6, and 8.5 W/m2). The 2.6 W/m2 scenario is the least extreme and the 8.5 W/m2 scenario is the most extreme.\n",
    "\n",
    "- Precipitation data is provided as a monthly mean of the daily precipitation rate in units of kg/m2s\n",
    "- Temperature data is provided as a monthly mean of the daily predicted temperature in units of degrees K\n",
    "\n",
    "### Coverage\n",
    "The data spatially covers the contiguous US at a spatial resolution of 30 arc-seconds/0.00833 degrees (approximately 800 meters). The temoporal coverage of the data is made up of a \"Retrosoective Run\" (1950-2005), and a \"Prospective Run\" (2006-2099).\n",
    "\n",
    "### File Format\n",
    "Data is in netcdf files. It contains the following information:\n",
    "- One monthly averaged value for each month from 2006 to 2099\n",
    "- Monthly average can be based off of daily min, max, average and quartiles for each constituent\n",
    "- Your selected file will contain the variables you request for the spatial and temporal subset you specify in the NetcdfSubset access url \n",
    "\n",
    "### Retrieval\n",
    "This dataset will be downloaded directly from its access point on the internet. It will be downloaded through the xarray package.\n",
    "\n",
    "### Assumptions\n",
    "Relative spatial patterns in temperature and precipitation observed from 1950 through 2005 will remain constant under future climate change. \n",
    "\n",
    "Does not add information beyond what is contained in the original CMIP5 scenarios, and preserves the frequency of periods of anomalously high and low temperature or precipitation (i.e., extreme events) within each individual CMIP5 scenario.\n",
    "\n",
    "### Bias Correction-Spatial Disaggregation (BSCD)\n",
    "***Problem: Biased data unsuitable for local level decision making.*** \n",
    "\n",
    "Original GCM model runs are run at coarse resolution which is not at the level of detail required for local decision making. In addition, although the projections are globally accurate there may be considerable bias at the local level since it does not take into account local topography.\n",
    "\n",
    "***Solution: BSCD using PRISM (observational climate data from meteorological stations)***\n",
    "\n",
    "The Bias-Correction step corrects the bias of the GCM data through comparisons performed against the observationally-based PRISM data.\n",
    "The Spatial-Disaggregation step spatially interpolates the bias-corrected GCM data to the finer resolution grid of the 30-arc second PRISM data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5cb75-cb54-4708-8b88-459cae2ca17d",
   "metadata": {},
   "source": [
    "<a id='io'></a> \n",
    "## Dataset Input/Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9080a2-6b0e-4269-b801-dbd8b5b14b3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pj/hjkdvsy93m7by3c44dw8fz3r0000gp/T/ipykernel_16073/1122546967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mccrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xarray'"
     ]
    }
   ],
   "source": [
    "# Import all necessary packages (matplotlib, numpy, etc)\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import geopandas as gpd\n",
    "import metpy\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644db2fb-0441-45fe-95fd-4ed63e50e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# location of NEXDCP30 data\n",
    "nexdcp_url=\"https://ds.nccs.nasa.gov/thredds/dodsC/bypass/NEX-DCP30/nex-quartile/rcp85/r1i1p1.ncml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e09ff-4bda-4a28-92bd-84295bd0c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset using remote URL\n",
    "nexdcp_rcp85_xr=xr.open_dataset(nexdcp_url)\n",
    "\n",
    "# display dataset to see what it looks like\n",
    "nexdcp_rcp85_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48976caf-5562-44d5-bce9-3d21bf4f5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Santa Barbara County shapefile\n",
    "sb_county = gpd.read_file('tl_2019_06083_faces/tl_2019_06083_faces.shp')\n",
    "\n",
    "xmin, ymin, xmax, ymax = sb_county.total_bounds\n",
    "xmin_shift = xmin + 360\n",
    "xmax_shift = xmax + 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff38b7-93ee-46ad-bcf5-124bc7a5b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single x,y combination closest to Santa Barbara city location\n",
    "key1=639\n",
    "key2=1243\n",
    "longitude = nexdcp_rcp85_xr[\"ens-avg_tasmax\"][\"lon\"].values[key1]\n",
    "latitude = nexdcp_rcp85_xr[\"ens-avg_tasmax\"][\"lat\"].values[key2]\n",
    "\n",
    "print(\"Long, Lat values:\", longitude, latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30253e61-0707-4540-9c86-9afc6df27958",
   "metadata": {},
   "source": [
    "<a id='display'></a> \n",
    "### Metadata Display and Basic Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fb13aa-3480-4b7c-9990-15aac3572fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Visualization\n",
    "# Create a spatial map of your selected location with cartopy\n",
    "extent = [xmin, xmax, ymin, ymax]\n",
    "central_lon = np.mean(extent[:2])\n",
    "central_lat = np.mean(extent[2:])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6),\n",
    "                     subplot_kw={'projection': ccrs.AlbersEqualArea(central_lon, central_lat)})\n",
    "ax.coastlines()\n",
    "# Plot the selected location \n",
    "ax.plot(longitude-360, latitude, \n",
    "        'r*', \n",
    "        transform=ccrs.PlateCarree(),\n",
    "       color=\"purple\", markersize=10)\n",
    "\n",
    "ax.set_extent(extent)\n",
    "ax.set(title=\"Location of Santa Barbara\")\n",
    "\n",
    "# Adds continent boundaries to the map\n",
    "ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "\n",
    "ax.gridlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155cc4a-4159-44d3-8111-642f1dd06316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the data spatially using a single lat/lon point\n",
    "start_date = \"2022-01-15\"\n",
    "end_date = \"2099-12-15\"\n",
    "sb_max_temp = nexdcp_rcp85_xr[\"ens-avg_tasmax\"].sel(time=slice(start_date, end_date),\n",
    "                                                lat=latitude,\n",
    "                                                lon=longitude)\n",
    "sb_avg_precip = nexdcp_rcp85_xr[\"ens-avg_pr\"].sel(time=slice(start_date, end_date),\n",
    "                                                lat=latitude,\n",
    "                                                lon=longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f346a97-f280-47c2-8f9d-7f75cbdf16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert temperature data from Kelvin to Farenheit\n",
    "sb_max_temp = sb_max_temp.metpy.convert_units('degF')\n",
    "# Conversion factor 1 kg/m2/s = 86400 mm/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d767b-3b79-44de-bbf3-b4295193024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metpy.units import units\n",
    "\n",
    "# this will create a Pint Quantity giving our masked array physical units\n",
    "\n",
    "density_water = units('kg / m^3') * 1000\n",
    "sb_avg_precip_converted_int = (sb_avg_precip / density_water)\n",
    "sb_avg_precip_converted = sb_avg_precip_converted_int.metpy.convert_units('inches / hour')  \n",
    "sb_avg_precip_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11253aec-198a-4ed9-8f65-844839e4731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_max_temp_ds = sb_max_temp.to_dataset()\n",
    "sb_max_temp_ds\n",
    "sb_avg_precip_ds = sb_avg_precip_converted.to_dataset()\n",
    "sb_avg_precip_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d49a5d-6b1e-4e91-93ee-16f685dbd5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = sb_max_temp_ds.to_pandas()\n",
    "precip_df = sb_max_temp_ds.to_pandas()\n",
    "temp_df['time'] = temp_df.index\n",
    "precip_df['time'] = precip_df.index\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521eece-61e8-4d24-bbfe-622d77c2ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_df['time'].days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e6a56-f534-441c-a779-8b98cd5c2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more conversion stuff for precipitation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d413ed9-9f49-4b6e-9773-83909b50ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopped pulling in dtuff from Desik's copy here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62354cdf-609f-487d-be51-9ea306997a69",
   "metadata": {},
   "source": [
    "<a id='usecases'></a> \n",
    "### Use Case Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7248ffea-5a88-4f92-8326-d45332463214",
   "metadata": {},
   "source": [
    "### Use Case 1: Protecting your county from heat\n",
    "\n",
    "Congratulations!! You are part of the Santa Barbara County Climate Change Task Force (SBCCCTF). You have been hired to use data analysis to determine the areas where temperature increase will occur most drastically in the county for X, y, and z years. You are charged with making a map that shows the temperature increases. \n",
    "\n",
    "This analysis and map will be critical to determine which areas will be most susceptible to heat waves in the future. County and city officials will use your analysis to determine the most vulnerable populations in the county to heat waves. Your analysis will help save lives as there are more extreme heat events in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab861747-f39f-4dfb-b00b-a3724428318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b3795-25b8-4295-b61a-347759552951",
   "metadata": {},
   "source": [
    "We now know that the x, y, and z areas of a county will be most vulnerable to increasing temperatures in the future. Further analysis should include looking at previous heat wave events and determining patterns of health issues related to the events. City data could be used to find suitible buildings to be set up as cooling shelters during these events for those that do not have air conditioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830372f1-ad26-4a8d-8030-a42a5eacfe13",
   "metadata": {},
   "source": [
    "### Use case 2: You are a big shot wine investor.\n",
    "\n",
    "Grapevines can be used to make wine for decades and even as long as 100 years! You, a big shot wine investor want to make sure that your investment will be protected from climate change. To protect and plan for climate change you want to determine how predicted rainfall will change throughout your favorite region, Santa Barbara County.\n",
    "\n",
    "To conduct this analysis you will make a map of the region and determine the predicted total rainfall for years x, y, and z. This information will then be provided to your growers in the region to determine whether they will need to plan for reduced, increased, or stagnant rainfalls. With this information they will tell you whether your current grapes will be climate change resilient or whether or not you should consider planting different types of grapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d6172-e139-426f-acb7-da7ef58e6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464af56-22ba-4af3-90cd-9dbff8c49ec4",
   "metadata": {},
   "source": [
    "We now know what the future of rainfall in Santa Barbara is predicted to look like under the worst case climate change scenario according to this dataset. The good news for you is that your crop in this region will be relatively protected. With this base analysis you have determined that it is critical to expand your research into all of your west coast vineyards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b04a9-b2bb-40ed-bb8c-9c75d3494c38",
   "metadata": {},
   "source": [
    "This is the \"meat\" of the notebook, and what will take the majority of the time to present in class. This section should provide:\n",
    "1) A plain-text summary (1-2 paragraphs) of the use case example you have chosen: include the target users and audience, and potential applicability. For example, the Week 7 SST exercise might discuss how the state of the ENSO system can be important for seasonal weather forecasts/coral bleaching outlooks, then mention the typical diagnostics associated with ENSO (i.e. identification of El Nino/La Nina events).\n",
    "\n",
    "2) Markdown and code blocks demonstrating how one walks through the desired use case example. This should be similar to the labs we've done in class: you might want to demonstrate how to isolate a particularly interesting time period, then create an image showing a feature you're interested in, for example.\n",
    "\n",
    "3) A discussion of the results and how they might be extended on further analysis. For example, we are doing El Nino/La Nina composites in class; a natural extension might be to look at individual events to see what their particular impacts were. Or if there are data quality issues which impact the results, you could discuss how these might be mitigated with additional information/analysis.\n",
    "\n",
    "Just keep in mind, you'll have roughly 20 minutes for your full presentation, and that goes surprisingly quickly! Probably 2-3 diagnostics is the most you'll be able to get through (you could try practicing with your group members to get a sense of timing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07de0d-1e81-442a-a895-7b7fd7906385",
   "metadata": {},
   "source": [
    "<a id='binder'></a> \n",
    "### Create Binder Environment\n",
    "\n",
    "The last step is to create a Binder environment for your project, so that we don't have to spend time configuring everyone's environment each time we switch between group presentations. Instructions are below:\n",
    "\n",
    " - Assemble all of the data needed in your Github repo: Jupyter notebooks, a README file, and any datasets needed (these should be small, if included within the repo). Larger datasets should be stored on a separate server, and access codes included within the Jupyter notebook as discussed above. \n",
    " \n",
    " - Create an _environment_ file: this is a text file which contains information on the packages needed in order to execute your code. The filename should be \"environment.yml\": an example that you can use for the proper syntax is included in this template repo. To determine which packages to include, you'll probably want to start by displaying the packages loaded in your environment: you can use the command `conda list -n [environment_name]` to get a list.\n",
    " \n",
    " More information on environment files can be found here:\n",
    " https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#\n",
    "\n",
    " - Create Binder. Use http://mybinder.org to create a  URL for your notebook Binder (you will need to enter your GitHub repo URL). You can also add a Launch Binder button directly to your GitHub repo, by including the following in your README.md:\n",
    "\n",
    "```\n",
    "launch with myBinder\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/<path to your repo>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c774b-8a7c-4f47-9c07-7f9823c48473",
   "metadata": {},
   "source": [
    "<a id='references'></a> \n",
    "### References\n",
    "\n",
    "List relevant references. Here are some additional resources on creating professional, shareable notebooks you may find useful:\n",
    "\n",
    "1. Notebook sharing guidelines from reproducible-science-curriculum: https://reproducible-science-curriculum.github.io/publication-RR-Jupyter/\n",
    "2. Guide for developing shareable notebooks by Kevin Coakley, SDSC: https://github.com/kevincoakley/sharing-jupyter-notebooks/raw/master/Jupyter-Notebooks-Sharing-Recommendations.pdf\n",
    "3. Guide for sharing notebooks by Andrea Zonca, SDSC: https://zonca.dev/2020/09/how-to-share-jupyter-notebooks.html\n",
    "4. Jupyter Notebook Best Practices: https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69\n",
    "5. Introduction to Jupyter templates nbextension: https://towardsdatascience.com/stop-copy-pasting-notebooks-embrace-jupyter-templates-6bd7b6c00b94  \n",
    "    5.1. Table of Contents (Toc2) readthedocs: https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html  \n",
    "    5.2. Steps to install toc2: https://stackoverflow.com/questions/23435723/installing-ipython-notebook-table-of-contents\n",
    "6. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLOS Computational Biology 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007. Supplementary materials: example notebooks (https://github.com/jupyter-guide/ten-rules-jupyter) and tutorial (https://github.com/ISMB-ECCB-2019-Tutorial-AM4/reproducible-computational-workflows)\n",
    "7. Languages supported by Jupyter kernels: https://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n",
    "8. EarthCube notebooks presented at EC Annual Meeting 2020: https://www.earthcube.org/notebooks\n",
    "9. Manage your Python Virtual Environment with Conda: https://towardsdatascience.com/manage-your-python-virtual-environment-with-conda-a0d2934d5195\n",
    "10. Venv - Creation of Virtual Environments: https://docs.python.org/3/library/venv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f10df5-100c-4f4a-a1c3-bd417b524a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
